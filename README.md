MalGenie: Automated Malware Generation with Large Language Models

Frontier Large Language Models (LLMs) have shown a remarkable ability to write code. However, LLMs have been shown to be susceptible to ‘jailbreak’ attacks that remove the models’ defenses against generating nefarious content. We investigate the potential abilities of LLMs to 
generate functional malware programs from simple text descriptions, developing a new research tool, MalGenie, to understand the dangerous potential of LLMs creating malware with only limited human guidance.
